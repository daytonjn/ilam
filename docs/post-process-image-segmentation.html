<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Post-Process Image Segmentation | iLAM: imaging Locomotor Activity Monitor</title>
  <meta name="description" content="This is the documentation for the iLAM project, a monitor to quantify diel and circadian insect activity" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Post-Process Image Segmentation | iLAM: imaging Locomotor Activity Monitor" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the documentation for the iLAM project, a monitor to quantify diel and circadian insect activity" />
  <meta name="github-repo" content="ilam/daytonjn.github.io/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Post-Process Image Segmentation | iLAM: imaging Locomotor Activity Monitor" />
  
  <meta name="twitter:description" content="This is the documentation for the iLAM project, a monitor to quantify diel and circadian insect activity" />
  

<meta name="author" content="Jacob Dayton &amp; Avalon Owens" />


<meta name="date" content="2023-08-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="raspberry-pi-zero-wcamera-setup.html"/>
<link rel="next" href="make-dam-output.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">iLAM</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Description</a></li>
<li class="chapter" data-level="2" data-path="flight-cage-construction.html"><a href="flight-cage-construction.html"><i class="fa fa-check"></i><b>2</b> Flight-Cage Construction</a></li>
<li class="chapter" data-level="3" data-path="raspberry-pi-zero-wcamera-setup.html"><a href="raspberry-pi-zero-wcamera-setup.html"><i class="fa fa-check"></i><b>3</b> Raspberry Pi Zero W/Camera Setup</a></li>
<li class="chapter" data-level="4" data-path="post-process-image-segmentation.html"><a href="post-process-image-segmentation.html"><i class="fa fa-check"></i><b>4</b> Post-Process Image Segmentation</a></li>
<li class="chapter" data-level="5" data-path="make-dam-output.html"><a href="make-dam-output.html"><i class="fa fa-check"></i><b>5</b> Make DAM Output</a></li>
<li class="chapter" data-level="6" data-path="analyze-output.html"><a href="analyze-output.html"><i class="fa fa-check"></i><b>6</b> Analyze Output</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">iLAM: imaging Locomotor Activity Monitor</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="post-process-image-segmentation" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Post-Process Image Segmentation<a href="post-process-image-segmentation.html#post-process-image-segmentation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Below is a walk-through for the post-process image segmentation (i.e., blob identification) of iLAM images</p>
<p><strong>1. Organize your file directory structure in a logical, hierarchical structure</strong></p>
<ul>
<li>Universal iLAM functions are within <code>~/iLAM/scripts/</code></li>
<li><code>~/iLAM/exp_a/</code> contains images, metadata, and analysis scripts specific to Experiment A</li>
<li>Experiment A’s images from ilam_01 and ilam_02 are saved in <code>~/iLAM/exp_a/ilam_01/</code> and <code>~/iLAM/exp_a/ilam_02/</code>, respectively</li>
<li>CSV output containing the size, location, and timing of all blobs/movements for each iLAM cages for Experiment A (i.e., ilam_01 and ilam_02):<code>~/iLAM/exp_a/iLAM_exp_a.txt/</code>, with corresponding metadata: <code>~/iLAM/exp_a/metadata_exp_a.csv/</code></li>
</ul>
<pre><code>##                           levelName
## 1  iLAM                            
## 2   ¦--exp_a                       
## 3   ¦   ¦--ilam_01                 
## 4   ¦   ¦   ¦--ilam01.0707.2058.jpg
## 5   ¦   ¦   °--ilam01.0707.2100.jpg
## 6   ¦   ¦--ilam_02                 
## 7   ¦   ¦   ¦--ilam02.0707.2058.jpg
## 8   ¦   ¦   °--ilam02.0707.2100.jpg
## 9   ¦   ¦--scripts                 
## 10  ¦   ¦   ¦--analyze_experiment.R
## 11  ¦   ¦   ¦--exp_a_ilam01.R      
## 12  ¦   ¦   ¦--exp_a_ilam02.R      
## 13  ¦   ¦   ¦--run_exp_a_ilam01.sh 
## 14  ¦   ¦   °--run_exp_a_ilam02.sh 
## 15  ¦   ¦--metadata_exp_a.csv      
## 16  ¦   °--iLAM_exp_a.txt          
## 17  ¦--exp_b                       
## 18  ¦   ¦--ilam_01                 
## 19  ¦   ¦--ilam_02                 
## 20  ¦   °--scripts                 
## 21  °--scripts                     
## 22      ¦--find_movements.R        
## 23      ¦--find_threshold.R        
## 24      ¦--make_dam_file.R         
## 25      ¦--make_gif.R              
## 26      ¦--parse_movements.R       
## 27      °--plot_movements.R</code></pre>
<p><strong>2. Perform image segmentation to identify movements across images taken by each iLAM (exp_a_ilam01.R, exp_a_ilam02.R, etc.)</strong></p>
<div class="figure" style="text-align: left"><span style="display:block;" id="fig:bb"></span>
<img src="images/segmentation_workflow.png" alt="Image segmentation workflow"  />
<p class="caption">
Figure 4.1: Image segmentation workflow
</p>
</div>
<ul>
<li>Load required packages and iLAM functions</li>
</ul>
<pre><code> library(imager)
 library(tidyverse)
 library(reshape2)
 library(dplyr)
 library(plyr)
 library(lubridate)
 library(readr)
 library(stringr)
 library(plotrix)

setwd(&quot;/~/iLAM/exp_a/&quot;)

 #read in iLAM functions
 for (f in list.files(&quot;../scripts&quot;, pattern=&quot;*.R&quot;,
                      full.names = TRUE)) {
   source(f)
</code></pre>
<ul>
<li>Update and tailor values for every cage and/or experiment; these values are recorded to metadata output and used as input settings for the <em>find_movements()</em> iLAM wrapper function:
<ul>
<li><strong>Cage-Specific:</strong> Integer coordinates for image cropping (x_left, x_right, y_bot, y_top)</li>
<li><strong>Experiment-Specific:</strong>
<ul>
<li><em>n_thr:</em> Numeric threshold percentile; higher values indicate a more stringent filtering. e.g., at n_thr=0.999, only the darkest pixel differences &gt;99.9% are retained for blob identification (default: n_thr = 0.996)</li>
<li><em>n_cln:</em> Integer value to clean up pixels; e.g., at n_cln = 5, this first “shrinks” to remove all isolated blobs smaller than 5 pixels, and then “grows” remaining blobs by 5*n_grw pixels to aggregate nearby blobs with each other. (default: n_cln = 5, n_grw = 1.5)</li>
<li><em>genus:</em> Character string for study organism</li>
<li><em>species:</em> Character string for study organism</li>
<li><em>color:</em> Character string to indicate whether the study organism appears “white” or “black” on the background</li>
<li>For more information on threshold, clean, blur, etc., see <a href="https://dahtah.github.io/imager/">imager documentation</a> for more details.</li>
</ul></li>
</ul></li>
</ul>
<pre><code>pi_sub_folder &lt;- &quot;ilam01&quot;
sex &lt;- &quot;male&quot; #cage/project-specific

#Crop-settings
x_left &lt;- 425 #cage-specific, depending on camera arrangement
x_right &lt;- 2225 #cage-specific, depending on camera arrangement
y_bot &lt;- 100 #cage-specific, depending on camera arrangement
y_top &lt;- 1700 #cage-specific, depending on camera arrangement

#change following values for every experiment
out_file_name = &quot;iLAM_exp_a&quot; #project-specific
n_thr = 0.999 #species-specific, depending on IR reflectance/contrast with background
n_cln = 10 #species-specific, depending on IR reflectance
n_max = 75000 #species-specific, pixel differences above this value will be considered as noise
start_photophase = 5 #project-specific, time that lights turn on
end_photophase = 21 #project-specific, time that dark starts
genus = &quot;photinus&quot; #project-specific
species = &quot;marginellus&quot; #project-specific
animal = &quot;black&quot; #project-specific, during the night, does the animal appear &quot;white&quot; on a dark background or &quot;black&quot; on a light background? This is VERY important (!) because it determines whether &quot;movements&quot; identify insects whom left vs. arrived between frames </code></pre>
<ul>
<li>Create a vector of .jpg image file names to be analyzed</li>
</ul>
<pre><code>file_names &lt;- list.files(pi_sub_folder,
                         pattern= &quot;*.jpg&quot;,
                         full.names = TRUE)</code></pre>
<p><em>We identify cropping locations that remove the outer edges of the cage, and maintain a constant picture area across all iLAMs (e.g., 1800x1600 pixels) by the following command:</em></p>
<pre><code>load.image(file_names[1]) %&gt;%
imsub(x %inr% c(x_left,x_right), y %inr% c(y_bot,y_top)) %&gt;% plot()</code></pre>
<ul>
<li>Find all movements by image subtraction, global thresholding, and blob detection in the iLAM wrapper function <code>find_movements()</code>.
-Additional <em>optional</em> settings:
<ul>
<li><em>n_blr:</em> Integer value to set blur radius to denoise image and reduce graininess, prior to image subtraction (default: n_blr = 3)</li>
<li><em>n_grw:</em> Integer value for n_cln multiplier to “grow” and aggregate blobs within a given proximity. For example, when n_cln=5 and n_grw = 1.5, blobs are first shrunk by 5 pixels and then grown by 5x1.5=7.5 pixels (default: n_grw = 1.5)</li>
<li><em>n_max:</em> Integer value denoting the maximum number of pixel differences expected between two images; any values above this n_max will be considered as noisy and assigned an arbitrary value for subsequent filtering/removal. See @ref(04-make_dam_output.Rmd) for more information. Example, if a moth movement = 3000 pixels and there are five moths in a cage, then the maximum number of differences expected is 15,000 pixels. (default: n_max = 75000)</li>
<li><em>find_thr:</em> Boolean value “T” (true) or “F” (false) to determine what pixel value cut-off corresponds to the n_thr percentile difference across a p_sample of image comparisons (default = “T”)</li>
<li><em>type_thr:</em> String value “absolute” or “relative” indicating whether to perform absolute (capture all differences &gt; n_thr for all pictures) or relative thresholding procedure (capture all differences &gt; n_thr for each comparison) on set of images. We recommend the default, “absolute” option because the latter identifies false movements in images where there are no movements because it always retains the top pixel differences. (default: find_thr = “absolute”)</li>
<li><em>p_sample:</em> Numeric value denoting the proportion of image comparisons that should be used to determine the absolute threshold valaue</li>
<li><em>channel:</em> String value denoting which color channel movements should be identified from (default: “grayscale”)</li>
</ul></li>
</ul>
<pre><code>out &lt;- find_movements(files = file_names, # list of file names 
                      n_thr = n_thr,      # threshold value (0.992 == &quot;0.8%&quot;)
                      n_cln = n_cln,      # value for cleaning (number of pixels)
                      n_grw = 1.5,      # multiplier for n_cln (shrink vs. grow)
                      n_blr = 3,          # let user select blur radius
                      n_max = 75000,      # upper cut-off for # pixel differences
                      x_left = x_left,    # value for crop on x min
                      x_right = x_right,  # value for crop on x max
                      y_bot = y_bot,      # value for crop on y min
                      y_top = y_top,      # value for crop on y max
                      find_thr = T, # T or F
                      type_thr = &quot;absolute&quot;,
                      p_sample = 0.05,    # If 5% of the total images &lt; 100, then increase this value
                      channel = &quot;grayscale&quot;,
                      animal = animal)</code></pre>
<ul>
<li>Update and save output containing all identified blobs, their size and location as a .csv in the current working directory.</li>
</ul>
<pre><code>#adds additional columns to dataframe
out$ID &lt;- paste0(n_thr*100,&quot;%_&quot;, &quot;s&quot;, n_cln, &quot;g&quot;, 1.5*n_cln)
out$sex &lt;- sex
out$genus &lt;- genus
out$species &lt;- species

if (file.exists(paste0(out_file_name,&quot;.csv&quot;))){
  write.table(out, file = paste0(out_file_name,&quot;.csv&quot;),
              append = TRUE, quote = TRUE, sep = &quot;,&quot;,
              row.names = FALSE, col.names = FALSE)
} else{
  write.csv(out, file = paste0(out_file_name,&quot;.csv&quot;),
            col.names = TRUE, row.names = FALSE)
  
}
rm(out)</code></pre>
<ul>
<li>Use <code>plot_movements()</code> to visualize movements by plotting detected blobs onto a subset of images</li>
</ul>
<pre><code>#circles in bottom left corner denote standards of sizes: 12.8k px, 3.2k px, 800 px, 200 px, 50 px
plot_movements(pi_sub_folder,
               by_change,
               x_left, x_right,
               y_bot, y_top)</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:j"></span>
<img src="images/ilam_plot_movement.jpg" alt="iLAM plot_movements() image"  />
<p class="caption">
Figure 4.2: iLAM plot_movements() image
</p>
</div>
<ul>
<li>If desired, make a gif from plotted images with <code>make_gif()</code></li>
</ul>
<pre><code>make_gif(out_file_name,
          pi_sub_folder)</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:k"></span>
<img src="images/ilam_photinus.gif" alt="iLAM make_gif() output"  />
<p class="caption">
Figure 4.3: iLAM make_gif() output
</p>
</div>
<p><em>Note: For more details/customization, look “under-the-hood” at the <code>find_movements()</code> and <code>find_threshold()</code> functions</em></p>
<p><strong>Tips:</strong>
- First test parameters settings for <code>find_movements()</code> with a subset of experimental images: e.g., <code>find_movements(files = file_names[1:100])</code>
- If find_movements() crashes, returns excess small blobs/movements, and/or returns excess blobs/movements that do NOT correspond to REAL movements, then increase the n_thr or p_sample values. If this issue continues, then remove any days at the experiment end where all/most insects have died; this can downwardly bias the # of pixel differences expected across images.
- If find_movements() returns many small blobs/animal and you desire one blob/animal movement, then increase the n_cln and/or n_grw values</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="raspberry-pi-zero-wcamera-setup.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="make-dam-output.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/daytonjn/ilam/edit/main/03-image_analysis.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/daytonjn/ilam/blob/main/03-image_analysis.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
